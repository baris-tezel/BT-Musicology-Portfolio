---
title: "Baris Tezel Computational Musicology"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
---


```{r}
```


### Track-Level Summaries


```{r}
library(tidyverse)
library(spotifyr)
library(compmus)
Aya_Naka <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "37i9dQZF1DZ06evO4zlQhH?si=2556e1ed8179453b"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
Stromae_Belgian <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "37i9dQZF1DX3NT4PRVyEpr?si=c639b1dce2344d94"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
Afro_Francophonic <-
  Aya_Naka %>%
  mutate(artist = "Aya") %>%
  bind_rows(Stromae_Belgian %>% mutate(artist = "Stromae"))



Afro_Francophonic %>%
  mutate(
    sections =
      map(
        sections,                                    # sections or segments
        summarise_at,
        vars(tempo, loudness, duration),             # features of interest
        list(section_mean = mean, section_sd = sd)   # aggregation functions
      )
  ) %>%
  unnest(sections) %>%
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = artist,
      alpha = loudness
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_minimal() +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    colour = "Artist",
    size = "Duration (min)",
    alpha = "Volume (dBFS)"
  )
```
***
Through this graph, I was able to see that Stromae, on average, had a higher average bmp for his songs in comparison to Aya. However, it seems that Aya's music had relatively similar Mean tempos. I wonder if this is in correlation to the fact that she is a rapper, I wonder if rapping is more conducive to similar levels of Mean Tempo. The graph also shows that Aya's music has relatively similar levels of Standard Deviation in Tempo. Again, I wonder if this in in correlation to the types of music that she produces in comparison to Stromae's music.

### Chodograms for the Song Ta Fete by Stromae

```{r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

tf <-
  get_tidy_audio_analysis("7fWWbkok99Tvh8aly2Buox?si=cda517b36c944da1") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"
      )
  )

tf %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "cosine",  # Try different distance metrics
    norm = "euclidean"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```
***
This chordogram is for the song Ta Fete by Stromae for the first 175 seconds. I am still in the process of really learning how to analyze these types of graphs. However, from my preliminary analysis it seems that Bb;major and Eb:major are the most prevalent chords in this song. B:major, E:major, and D:major is also quite prevalent in this song although not as much as the aforementioned two. At around the 100 seconds mark almost all of the chords except C#:minor and Db:major are incredibly prevalent for about 20 seconds. This could be because at this specific point of the music ____

### Self-Selection Matrixes

```{r}
library(tidyverse)
library(spotifyr)
library(compmus)

sapesjamais <-
  get_tidy_audio_analysis("0CJ31BEjjl1tPIj0CKi9kH?si=1d722c329b994433") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  sapesjamais %>%
    compmus_self_similarity(pitches, "aitchison") %>%
    mutate(d = d / max(d), type = "Chroma"),
  sapesjamais %>%
    compmus_self_similarity(timbre, "euclidean") %>%
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```
***
This is of the song, Sapes Comme Jamais, by Maitre Gims. I need help in interpreting graphs like this. The professor has done a great job so far but this specific type of graph is the hardest for me to interpet. I need more help. 

### Chromograms for Djaja, Sapes Commes Jamais, and Ta Fete.


```{r}
djaja <-
  get_tidy_audio_analysis("7sKDftgGirHWTVFMtJoDoh?si=7cfc7d2b067949da") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

djaja %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

sapes <-
  get_tidy_audio_analysis("0CJ31BEjjl1tPIj0CKi9kH?si=1d722c329b994433") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

sapes %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

Taf <-
  get_tidy_audio_analysis("7fWWbkok99Tvh8aly2Buox?si=cda517b36c944da1") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

Taf %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```
***
These are of the songs: Djaja by Aya, Sapes Comme Jamais by Gims, and Ta Fete by Stromae. I will label the graphs accordingly soon. Djaja has the highest magnitude at G, F, and C. For Sapes Commes Jamais has the highest prevalence in F#|Gb,C#|Db and B. Stromae's song Ta Fete has the highest variance. However, there was a huge concentration on C#|Db and B. 

### Ceptogram for Djaja, Sapes Commes Jamais, and Ta Fete. 

```{r}
djaj <-
  get_tidy_audio_analysis("7sKDftgGirHWTVFMtJoDoh?si=7cfc7d2b067949da") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

djaj %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()

sapescomme <-
  get_tidy_audio_analysis("0CJ31BEjjl1tPIj0CKi9kH?si=1d722c329b994433") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

sapescomme %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()

tafete <-
  get_tidy_audio_analysis("7fWWbkok99Tvh8aly2Buox?si=cda517b36c944da1") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

tafete %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()

```  
***
These are of the songs: Djaja by Aya, Sapes Comme Jamais by Gims, and Ta Fete by Stromae. I will label the graphs accordingly soon. In Djaja, it is concentrated mainly around c05 and c02. In fact c01-c06 is the most prominent for Aya's Djaja. Sapes Commes Jamais is definitely more spread out in it's concentration. However c02, has the highest magnitude through most of the 200 seconds. Stromae's Ta Fete also has a high magnitude in c02. However, c06 is also incredibly prevalent throughout this second. Overall, all three of these artists have the highest prevalanece throughout c01-04. 
  
### Introduction to my Corpus

```{r}
```

***
My corpus will be studying the similarities and differences between three Afro-Francophonic artists, Stromae, Maître Gims, and Aya Nakamura. I have always loved listening to Afro-Francophonic music. I am interested in discovering the differences between these artists and if their differing backgrounds plays a role in their songs. In terms of anticipated difference, Stromae is less Afro-pop and more of a techno/pop artist. Maître Gims and Aya Nakamura are rappers but Maître Gims is more of a vocalist. As a result, I want to see if there are bigger differences in tempo, danceabiltiy, and rythm. The core of all three musicians is pop, so I believe there will be a lot of similarities there. I am unsure of how the different musicians' songs will score on Spotify's measurements. Overall, Spotify has alot of the music produced by the artists. I'm unsure if there are gaps in the music selection on Spotify. Some atypical songs from Maitre Gims include: Sapés commes jamais and Hola Señorita. The song is Afro-pop but includes a lot of power vocal moments. Hola Señorita has a lot of Latin Influence and is song in both Spanish and French. Some typical songs from Stromae: Ta fête and Alors on Danse. Both of these songs are incredibly good club/techno/pop music. It is incredibly catchy and has really simple beats. Some typical songs from Aya Nakamura: Djaja and Copines. Both of these songs are incredibly well made Afro-pop/Rap music. However, it is quite a typical song associated to that genre of music.

### Preliminary Data Visualizations for 3 Afro-Francophonic Artists

```{r}
library(tidyverse)
library(spotifyr)
library(compmus)

AYA <- get_playlist_audio_features("", "37i9dQZF1DZ06evO4zlQhH?si=2556e1ed8179453b")
GIMS <- get_playlist_audio_features("", "37i9dQZF1DZ06evO0lhGr6?si=41c043a364be43d5")
STROMAE <- get_playlist_audio_features("", "37i9dQZF1DX3NT4PRVyEpr?si=c639b1dce2344d94")

artists <-
  bind_rows(
    AYA %>% mutate(category = "Aya Nakamura"),
    GIMS %>% mutate(category = "Maitre Gims"),
    STROMAE %>% mutate(category = "Stromae")
  )
artists %>%
  ggplot(aes(x = danceability)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(~category)

artists %>%                    # Start with awards.
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major")
  ) %>%
  ggplot(                     # Set up the plot.
    aes(
      x = danceability,
      y = tempo,
      size = loudness,
      colour = mode
    )
  ) +
  geom_point() +              # Scatter plot.
  geom_rug(size = 0.1) +  # Add 'fringes' to show data distribution
  facet_wrap(~category)
```

***
My graph for Homework Assignment Week 7: I am trying to study the correlation between tempo and danceability primarily. However, I am also looking at the impacts that loudness and mode has on danceability and tempo. It seems that lower tempos, result in a higher danceability rating. On average, Stromae's music seems to be the less loud. His music also seems the less danceable but does have a higher tempo rating (on average) than the other two artists. Aya Nakamura seems to have the lowest Tempo rating, there might be a correlation between rappers and lower tempo ratings. Since Maitre Gims is a mix of rapper and vocalist, it seems correct that on average, his music seems to score in between Stromae and Aya in terms of tempo and danceability.

### Conclusions

```{r}
```

***
I cannot pull any conclusions yet, as I am still in the preliminary processes of this portfolio. 


