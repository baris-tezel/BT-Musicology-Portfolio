---
title: "Baris Tezel Computational Musicology"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
---

### Introduction to my Corpus; The Three Afro-Francophonic Artists

```{r}
```

***
My corpus will be studying the similarities and differences between three Afro-Francophonic artists, Stromae, Maître Gims, and Aya Nakamura. I have always loved listening to Afro-Francophonic music. I am interested in discovering the differences between these artists and if their differing backgrounds plays a role in their songs. In terms of anticipated difference, Stromae is less Afro-pop and more of a techno/pop artist. Maître Gims and Aya Nakamura are rappers but Maître Gims is more of a vocalist. As a result, I want to see if there are bigger differences in tempo, danceabiltiy, and rythm. The core of all three musicians is pop, so I believe there will be a lot of similarities there. I am unsure of how the different musicians' songs will score on Spotify's measurements. Overall, Spotify has alot of the music produced by the artists. I'm unsure if there are gaps in the music selection on Spotify. Some atypical songs from Maitre Gims include: Sapés commes jamais and Hola Señorita. The song is Afro-pop but includes a lot of power vocal moments. Hola Señorita has a lot of Latin Influence and is song in both Spanish and French. Some typical songs from Stromae: Ta fête and Alors on Danse. Both of these songs are incredibly good club/techno/pop music. It is incredibly catchy and has really simple beats. Some typical songs from Aya Nakamura: Djaja and Copines. Both of these songs are incredibly well made Afro-pop/Rap music. However, it is quite a typical song associated to that genre of music.

<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DZ06evO4zlQhH?theme=0" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DZ06evO0lhGr6?theme=0" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DX3NT4PRVyEpr?theme=0" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>



### Preliminary Data Visualizations for 3 Afro-Francophonic Artists: Aya Nakamura, Stromae, and Maitre Gims. 

#### Bargraph 

```{r}
library(tidyverse)
library(tidymodels)
library(ggdendro)
library(heatmaply)
library(spotifyr)
library(compmus)

AYA <- get_playlist_audio_features("", "37i9dQZF1DZ06evO4zlQhH?si=2556e1ed8179453b")
GIMS <- get_playlist_audio_features("", "37i9dQZF1DZ06evO0lhGr6?si=41c043a364be43d5")
STROMAE <- get_playlist_audio_features("", "37i9dQZF1DX3NT4PRVyEpr?si=c639b1dce2344d94")

artists <-
  bind_rows(
    AYA %>% mutate(category = "Aya Nakamura"),
    GIMS %>% mutate(category = "Maitre Gims"),
    STROMAE %>% mutate(category = "Stromae")
  )
artists %>%
  ggplot(aes(x = danceability)) +
  geom_histogram(binwidth = 0.1) +
  facet_wrap(~category)
```
#### Scatterplot

```{r}
artists %>%                    # Start with awards.
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major")
  ) %>%
  ggplot(                     # Set up the plot.
    aes(
      x = danceability,
      y = tempo,
      size = loudness,
      colour = mode
    )
  ) +
  geom_point() +              # Scatter plot.
  geom_rug(size = 0.1) +  # Add 'fringes' to show data distribution
  facet_wrap(~category)
```


***
For this particular section, I wanted to create some preliminary graphs as a way to begin my portfolio. To begin, I am trying to study the correlation between tempo and danceability primarily. However, I am also looking at the impacts that loudness and mode has on danceability and tempo. All of these characteristics can interact in ways or show patterns that could be applicable to my portfolio. It seems that lower tempos, result in a higher danceability rating. On average, Stromae's music seems to be the less loud. His music also seems the less danceable but does have a higher tempo rating (on average) than the other two artists. Aya Nakamura seems to have the lowest Tempo rating, there might be a correlation between rappers and lower tempo ratings. Since Maitre Gims is a mix of rapper and vocalist, it seems correct that on average, his music seems to score in between Stromae and Aya in terms of tempo and danceability. 

<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DZ06evO4zlQhH?theme=0" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DZ06evO0lhGr6?theme=0" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DX3NT4PRVyEpr?theme=0" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

### Dendrograms 

```{r}
get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}  

stromaeplaylist <-
  get_playlist_audio_features("thisisstromae", "37i9dQZF1DX3NT4PRVyEpr?si=c639b1dce2344d94") %>%
  add_audio_analysis() %>%
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))

stromaeplaylist_juice <-
  recipe(
    track.name ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = stromaeplaylist
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>% 
  # step_range(all_predictors()) %>% 
  prep(stromaeplaylist %>% mutate(track.name = str_trunc(track.name, 20))) %>%
  juice() %>%
  column_to_rownames("track.name")

stromaeplaylist_dist <- dist(stromaeplaylist_juice, method = "euclidean")

stromaeplaylist_dist %>% 
  hclust(method = "single") %>% # Try single, average, and complete.
  dendro_data() %>%
  ggdendrogram()

```

***

This dendrogram showcases that Stomae's music has stayed relatively the same irregardless of time. **Je Cours** and *Bonne journée* are quite similar **Défiler** and **Repetto** even if they were released seven or eight years apart from each other. Even though songs like **Te Quiero** who is in the same album as the first two tracks is quite different. This means that there is a lot of variabiltiy within albums. Although, certain albums can be quite similar in terms of various characteristics. It seems there is no clear characteristic which identifies each album. However, it does seem that his new Album, **Multitude**, has as much variabikity as past albums. Songs like **Invanicu, avf, L'enfer, La solassitude** seem quite similar to each other. However, when listening to Stromae's music you can generally tell that it is his music due to his speicifc style.  

<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DX3NT4PRVyEpr?theme=0" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

### Tempogram for **Orphelin** by **Aya Nakamura**

```{r}
Orphelin <- 
  get_tidy_audio_analysis("7ypQ1PtbClW0Aqe1ewS7h7")
Orphelin %>%
tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

***

I decided to create a Tempgoram for the song **Orphelon** by Aya Nakamura. Overall, Orphelin by Aya Nakamura seemed to have the highest BPM out of any of the songs in my corpus. It scored a BPM of 199. Overall one of the Tempograms cannot reach past 160 BPM, which is not able to capture the BPM of the song. When I was personally conducting a TAP BPM, I also received a BPM of 190. The tempogram **shows alot of activity** through the entire tempogram which is incredibly interesting. The song is a mixture of electronic and afro-beats. This could be the result of the higher BPM. The song also has a lot of different beats and rhythsm which could convince the tempogram. 

<iframe src="https://open.spotify.com/embed/track/7ypQ1PtbClW0Aqe1ewS7h7" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

### Track-Level Summaries for **Aya Nakamura** and **Stromae**


```{r}
library(tidyverse)
library(spotifyr)
library(compmus)
Aya_Naka <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "37i9dQZF1DZ06evO4zlQhH?si=2556e1ed8179453b"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
Stromae_Belgian <-
  get_playlist_audio_features(
    "thesoundsofspotify",
    "37i9dQZF1DX3NT4PRVyEpr?si=c639b1dce2344d94"
  ) %>%
  slice(1:30) %>%
  add_audio_analysis()
Afro_Francophonic <-
  Aya_Naka %>%
  mutate(artist = "Aya") %>%
  bind_rows(Stromae_Belgian %>% mutate(artist = "Stromae"))



Afro_Francophonic %>%
  mutate(
    sections =
      map(
        sections,                                    # sections or segments
        summarise_at,
        vars(tempo, loudness, duration),             # features of interest
        list(section_mean = mean, section_sd = sd)   # aggregation functions
      )
  ) %>%
  unnest(sections) %>%
  ggplot(
    aes(
      x = tempo,
      y = tempo_section_sd,
      colour = artist,
      alpha = loudness
    )
  ) +
  geom_point(aes(size = duration / 60)) +
  geom_rug() +
  theme_minimal() +
  ylim(0, 5) +
  labs(
    x = "Mean Tempo (bpm)",
    y = "SD Tempo",
    colour = "Artist",
    size = "Duration (min)",
    alpha = "Volume (dBFS)"
  )
```

***
Through this graph, I was able to see that Stromae, on average, had a higher average bmp for his songs in comparison to Aya. However, it seems that Aya's music had relatively similar Mean tempos. I wonder if this is in correlation to the fact that she is a rapper, I wonder if rapping is more conducive to similar levels of Mean Tempo. The graph also shows that Aya's music has relatively similar levels of Standard Deviation in Tempo. Again, I wonder if this in in correlation to the types of music that she produces in comparison to Stromae's music. I am going to create a point which represents the mean tempo of both Artists so there is clearer difference. 

<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DZ06evO4zlQhH?theme=0" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

<iframe src="https://open.spotify.com/embed/playlist/37i9dQZF1DX3NT4PRVyEpr?theme=0" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>



### Chordograms for the Song **Ta Fete** by **Stromae**

```{r}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

tf <-
  get_tidy_audio_analysis("7fWWbkok99Tvh8aly2Buox?si=cda517b36c944da1") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"
      )
  )

tf %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "cosine",  # Try different distance metrics
    norm = "euclidean"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

***
This chordogram is for the song Ta Fete by Stromae for the first 175 seconds. I am still in the process of really learning how to analyze these types of graphs. However, from my preliminary analysis it seems that Bb;major and Eb:major are the most prevalent chords in this song. B:major, E:major, and D:major is also quite prevalent in this song although not as much as the aforementioned two. At around the 100 seconds mark almost all of the chords except C#:minor and Db:major are incredibly prevalent for about 20 seconds. This could be because at this specific point of the music ____

<iframe src="https://open.spotify.com/embed/track/0KFkeq7DYdj5OT8vMML6il" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

### Self-Selection Matrixes for **Sapes Commes Jamais** by **Maitre Gims**

```{r}
sapesjamais <-
  get_tidy_audio_analysis("0CJ31BEjjl1tPIj0CKi9kH?si=1d722c329b994433") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "acentre", norm = "manhattan"
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  )
bind_rows(
  sapesjamais %>%
    compmus_self_similarity(pitches, "aitchison") %>%
    mutate(d = d / max(d), type = "Chroma"),
  sapesjamais %>%
    compmus_self_similarity(timbre, "euclidean") %>%
    mutate(d = d / max(d), type = "Timbre")
) %>%
  mutate() %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  facet_wrap(~type) +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```

***
These self-similarity matrices are to represent Sapes Comme Jamais by Maitre Gims.It seems as if the Chroma and Timbre graphs light up the most in a patchwork type pattern. Specifically it is the greenest on the 50 and 110 second marks. This could because the timbre and chroma values are the most similar at this point in the graph. 

<iframe src="https://open.spotify.com/embed/track/0CJ31BEjjl1tPIj0CKi9kH" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

### Chromograms for **Djaja, Sapes Commes Jamais, and Ta Fete.**

#### **Djaja by Aya Nakamura**

```{r}
djaja <-
  get_tidy_audio_analysis("7sKDftgGirHWTVFMtJoDoh?si=7cfc7d2b067949da") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

djaja %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

#### **Sapes Commes Jamais by Maitre Gims**

```{r}
sapes <-
  get_tidy_audio_analysis("0CJ31BEjjl1tPIj0CKi9kH?si=1d722c329b994433") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

sapes %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

#### **Ta Fete by Stromae**

```{r}
Taf <-
  get_tidy_audio_analysis("7fWWbkok99Tvh8aly2Buox?si=cda517b36c944da1") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

Taf %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

***
These are of the songs: Djaja by Aya, Sapes Comme Jamais by Gims, and Ta Fete by Stromae. Djaja has the highest magnitude at G, F, and C. For Sapes Commes Jamais has the highest prevalence in F#|Gb,C#|Db and B. Stromae's song Ta Fete has the highest variance. However, there was a huge concentration on C#|Db and B. 

<iframe src="https://open.spotify.com/embed/track/7sKDftgGirHWTVFMtJoDoh" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

<iframe src="https://open.spotify.com/embed/track/0CJ31BEjjl1tPIj0CKi9kH" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

<iframe src="https://open.spotify.com/embed/track/0KFkeq7DYdj5OT8vMML6il" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

### Ceptogram for **Djaja, Sapes Commes Jamais, and Ta Fete.** 

#### **Djaja by Aya Nakamura**

```{r}
djaj <-
  get_tidy_audio_analysis("7sKDftgGirHWTVFMtJoDoh?si=7cfc7d2b067949da") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

djaj %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```  

#### **Sapes Commes Jamais by Maitre Gims**

```{r}
sapescomme <-
  get_tidy_audio_analysis("0CJ31BEjjl1tPIj0CKi9kH?si=1d722c329b994433") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

sapescomme %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```

#### **Ta Fete by Stromae**

```{r}
tafete <-
  get_tidy_audio_analysis("7fWWbkok99Tvh8aly2Buox?si=cda517b36c944da1") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

tafete %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic()
```


***
These are of the songs: Djaja by Aya, Sapes Comme Jamais by Gims, and Ta Fete by Stromae. I will label the graphs accordingly soon. In Djaja, it is concentrated mainly around c05 and c02. In fact c01-c06 is the most prominent for Aya's Djaja. Sapes Commes Jamais is definitely more spread out in it's concentration. However c02, has the highest magnitude through most of the 200 seconds. Stromae's Ta Fete also has a high magnitude in c02. However, c06 is also incredibly prevalent throughout this second. Overall, all three of these artists have the highest prevalanece throughout c01-04. I wonder if this is due to the link of them all being Afro-Francophonic artists. That commonality could be what links them together and creates a ceptogram that has a similar concentration. 

<iframe src="https://open.spotify.com/embed/track/7sKDftgGirHWTVFMtJoDoh" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

<iframe src="https://open.spotify.com/embed/track/0CJ31BEjjl1tPIj0CKi9kH" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>

<iframe src="https://open.spotify.com/embed/track/0KFkeq7DYdj5OT8vMML6il" width="100%" height="380" frameBorder="0" allowtransparency="true" allow="encrypted-media"></iframe>
  

### Conclusions

```{r}
```

***

I decided to create a corpus which tried to study three Afro-Francophonic artists: Aya Nakamura, Maitre Gims, and Stromae. There was a lot of similarties between the artists such as their ptiches or chords. This could be due to the fit into the Pop and Rap genres that their music falls into. However, there were also some interesting differences that were discovered. These differences such as in loudness or tempo, could be attribute to the different styles of music that these artists have even if their songs are in similar genres. Stromae is more of a pop vocalist with certain songs that incorporate rap or spoken word. Aya Nakamura, is a rapper which can influence her songs. However, Maitre Gims is a mix between Aya Nakamura and Stromae as he is a rapper and vocalist. This could be the reason why he scores in between Aya and Stromae quite often. 

